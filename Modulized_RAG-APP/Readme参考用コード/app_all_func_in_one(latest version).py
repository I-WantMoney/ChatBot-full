import os
import streamlit as st
from dotenv import load_dotenv
from langchain_core.messages import AIMessage, HumanMessage
from langchain_core.prompts import ChatPromptTemplate,MessagesPlaceholder
from langchain.text_splitter import CharacterTextSplitter
from langchain_openai import ChatOpenAI,OpenAIEmbeddings
from langchain_community.document_loaders import UnstructuredFileLoader
from langchain_community.vectorstores.chroma import Chroma
from langchain.docstore.document import Document
from langchain.chains import create_history_aware_retriever,create_retrieval_chain
from langchain.chains.combine_documents import create_stuff_documents_chain

current_dir = os.path.dirname(os.path.abspath(__file__))
llm_model = os.environ["OPENAI_API_MODEL"]
load_dotenv()

# new added --------------------------

def get_text_from_file(allfile):
    text_list = []
    # ã‚»ãƒƒã‚·ãƒ§ãƒ³å†…ã®Docx_sã¨æ¯”è¼ƒã—ã¦ã€æ–°ã—ãè¿½åŠ ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã®ã¿ã‚’ãƒ†ã‚­ã‚¹ãƒˆã«å¤‰æ›
    temp_file = st.session_state.file_s
    if st.session_state.file_s != allfile:
        st.session_state.file_s = allfile
        print("We got new file(s)")
        for file in allfile:
            if file not in temp_file:
                file_path = os.path.join(current_dir,"temp_uploadedfiles",file.name)
                with open(file_path, "wb") as f:
                    f.write(file.getbuffer())
                    
                loader = UnstructuredFileLoader(file_path)
                file_doc = loader.load()
                text_list += file_doc
                os.remove(file_path)
        file_raw_doc = text_list
    #ã€€è¿½åŠ ãƒ•ã‚¡ã‚¤ãƒ«ã®ãªã„å ´åˆã€ç©ºlistã«ã™ã‚‹
    else:
        file_raw_doc = []
        
    return file_raw_doc
# ãƒãƒ£ãƒ³ã‚¯è¨­å®š
def get_chunks(full_doc):
    text_splitter = CharacterTextSplitter(
        separator = "\n| |\n\n",
        chunk_size = 1000,
        chunk_overlap = 200,
        length_function = len
    )
    
    chunks = text_splitter.split_documents(full_doc)
    
    return chunks

# ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢ç”Ÿæˆ
def get_vectorstore(chunks):
    embeddings = OpenAIEmbeddings()
    vectorstore = Chroma.from_documents(documents=chunks,embedding=embeddings)
    
    return vectorstore

def get_context_retriever_chain(vector_store):
    llm = ChatOpenAI(model=llm_model) # ã‚«ãƒƒã‚³å†…ã§api-keyã®æŒ‡å®šã€ãƒ¢ãƒ‡ãƒ«ã®æŒ‡å®šãªã©ãŒã§ãã¾ã™ã€‚ã‚³ãƒ¼ãƒ‰ã®å…ˆé ­ã«dotenvã‚’ä½¿ã£ãŸã®ã§ã€è‡ªå‹•çš„ã«.envãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰api-keyã‚’å–å¾—ã—ã¾ã™
    retriever = vector_store.as_retriever()
    prompt = ChatPromptTemplate.from_messages([
        MessagesPlaceholder(variable_name="chat_history"),
        ("user","{input}"),
        ("user","Given the above conversation, generate a search query to look up in order to get information relevant to the conversation")
    ])
    
    retriever_chain = create_history_aware_retriever(llm,retriever,prompt)
    
    return retriever_chain

def get_conversational_rag_chain(retriever_chain):
    
    llm = ChatOpenAI(model=llm_model) # ã‚«ãƒƒã‚³å†…ã§api-keyã®æŒ‡å®šã€ãƒ¢ãƒ‡ãƒ«ã®æŒ‡å®šãªã©ãŒã§ãã¾ã™ã€‚ã‚³ãƒ¼ãƒ‰ã®å…ˆé ­ã«dotenvã‚’ä½¿ã£ãŸã®ã§ã€è‡ªå‹•çš„ã«.envãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰api-keyã‚’å–å¾—ã—ã¾ã™
    prompt = ChatPromptTemplate.from_messages([
        ("system","Answer the user's questions based on the below context:\n\n{context}"),
        MessagesPlaceholder(variable_name="chat_history"),
        ("user","{input}")
    ])
    
    stuff_documents_chian = create_stuff_documents_chain(llm,prompt)
    
    return create_retrieval_chain(retriever_chain,stuff_documents_chian)

def get_response(user_input):
    
    
    retriever_chain = get_context_retriever_chain(st.session_state.vector_store)    
    conversation_rag_chain = get_conversational_rag_chain(retriever_chain)

    response = conversation_rag_chain.invoke({
        "chat_history": st.session_state.chat_history,
        "input": user_input
    })
    
    return response['answer']

# ãƒœã‚¿ãƒ³ã®ã‚¯ãƒªãƒƒã‚¯çŠ¶æ…‹è¨­å®šã®é–¢æ•°
def click_button():
    st.session_state.clicked = True

def main():
    
    # app config
    st.set_page_config(page_title="Chat with your files", page_icon="ğŸ¤–")
    st.title("Upload files and chat with them")
    st.info("Click the :red[_Process_] button before asking questions\n(:red[_Only the first time you upload_])")
    
    # ãƒœã‚¿ãƒ³ã®ã‚¯ãƒªãƒƒã‚¯çŠ¶æ…‹ã®åˆæœŸåŒ–è¨­å®š
    if "clicked" not in st.session_state:
        st.session_state.clicked = False   
    
    # ãƒ•ã‚¡ã‚¤ãƒ«å­˜åœ¨æƒ…æ³ã®åˆæœŸåŒ–
    if "file_s" not in st.session_state:
        st.session_state.file_s = [] 
    
    # ----ã®åˆæœŸåŒ–
    if "full_doc" not in st.session_state:
        st.session_state.full_doc = []
    # ----ã®åˆæœŸåŒ–
    if "vector_store" not in st.session_state:
        st.session_state.vector_store = None
     
    # ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®è¨­å®š
    with st.sidebar:
        # file upload
        st.title("Settings")
        st.header("",divider="rainbow")
        
        st.subheader("_Upload_ a :rainbow[FILE] :books:")
        allfile = st.file_uploader("Upload your FILE here and click on '_Process_'",accept_multiple_files=True,type=["xlsx","docx","pdf"])
        
        st.header("",divider="blue")
    
    # ãƒœã‚¿ãƒ³
    st.button("Process", on_click=click_button)
    # æœ€åˆã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æ™‚ã«ã‚¯ãƒªãƒƒã‚¯ã™ã‚Œã°ååˆ†
    # ã‚¯ãƒªãƒƒã‚¯ã•ã‚ŒãŸã‚‰ã€ãã®çŠ¶æ…‹ã‚’ã‚»ãƒƒã‚·ãƒ§ãƒ³ã«ä¿å­˜  
    if st.session_state.clicked:
        
        # latest ---------------------------------------------
        if allfile == []:
            file_existance = False
            file_raw_doc = []
            st.info(":red[_Enter a URL or Upload some files_]")
        
        else:
            file_existance = True
            file_raw_doc = get_text_from_file(allfile)
            full_doc_add = file_raw_doc
            st.session_state.full_doc += full_doc_add
        # ------------------------------------------------  
                
            print (f"Added doc: {full_doc_add}")
            if "chat_history" not in st.session_state:
                st.session_state.chat_history = [
                    AIMessage(content = "Hello, I am a a bot"),
                ]
            # æ–™é‡‘ç¯€ç´„ã®ãŸã‚ã«ã€è¿½åŠ ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãŒã‚ã‚‹ã¨ãã®ã¿ã€Embeddingã‚’åŸ·è¡Œ
            if full_doc_add != []:
                print("new file(s) added")
                print(f"Full doc: {st.session_state.full_doc}")
                chunks = get_chunks(st.session_state.full_doc)
                st.session_state.vector_store = get_vectorstore(chunks)
            else:
                print(st.session_state.full_doc)
                print("no file added")
            
            # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ã‚¯ã‚¨ãƒªãƒ¼ã§å›ç­”ã‚’ç”Ÿæˆ
            user_query = st.chat_input("Try asking something about your files ")
        
            if user_query is not None and user_query != "":
                response = get_response(user_query)
                # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã¨AIã®å›ç­”ã‚’ã‚»ãƒƒã‚·ãƒ§ãƒ³ã«å…¥ã‚Œã‚‹
                st.session_state.chat_history.append(HumanMessage(content=user_query))
                st.session_state.chat_history.append(AIMessage(content=response))

            # ç”»é¢ä¸Šã§è¡¨ç¤º
            for message in st.session_state.chat_history:
                if isinstance(message,AIMessage):
                    with st.chat_message("AI"):
                        st.write(message.content)
                elif isinstance(message,HumanMessage):
                    with st.chat_message("Human"):
                        st.write(message.content)
                     
if __name__ == "__main__":
    main()
    

